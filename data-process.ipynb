{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import hpacellseg.cellsegmentator as cellsegmentator\n",
    "from hpacellseg.utils import label_cell, label_nuclei\n",
    "from skimage import measure, segmentation, morphology\n",
    "import cv2\n",
    "from glob import glob\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Interface"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You need to run this with the absolute path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ishang/HPA-embedding/dev-dataset/11_TileScan 6--Stage00\n",
      "/home/ishang/HPA-embedding/dev-dataset/10_R1--Stage01\n",
      "/home/ishang/HPA-embedding/dev-dataset/field--X01--Y00_image--L0000--S00--U08--V04--J17--E02--O02--X01--Y00--T0000--Z00--C0\n"
     ]
    }
   ],
   "source": [
    "!find /home/ishang/HPA-embedding/dev-dataset -type d > data-folder.txt\n",
    "!sed -i '1d' data-folder.txt\n",
    "!cat data-folder.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/ishang/HPA-embedding/dev-dataset\") # NEEDS TO BE ABSOLUTE PATH\n",
    "CHANNEL_NAMES = [\"cyclinb1\", \"microtubule\", \"nuclei\"]\n",
    "DAPI = 2\n",
    "TUBL = 1\n",
    "ANLN = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT RERUN THIS CELL BELOW!!! YOU WILL HAVE TO KILL THE PROCESS AND RESTART THE KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "please compile abn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'pytorch_zoo.unet.DPNUnet' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.container.Sequential' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.conv.Conv2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.activation.ReLU' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.upsampling.Upsample' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.batchnorm.BatchNorm2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n",
      "/home/ishang/miniconda3/envs/data-prep/lib/python3.8/site-packages/torch/serialization.py:671: SourceChangeWarning: source code of class 'torch.nn.modules.pooling.MaxPool2d' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "pwd = Path(os.getcwd())\n",
    "NUC_MODEL = pwd / \"HPA-Cell-Segmentation\" / \"nuclei-model.pth\"\n",
    "CELL_MODEL = pwd / \"HPA-Cell-Segmentation\" / \"cell-model.pth\"\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:512\"\n",
    "segmentator = cellsegmentator.CellSegmentator(\n",
    "    str(NUC_MODEL), str(CELL_MODEL), device=\"cuda\", padding=True, multi_channel_model=(ANLN is not None)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO NOT RERUN THIS ^^^^^ YOU WILL HAVE TO KILL THE PROCESS AND RESTART THE KERNEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/home/ishang/HPA-embedding/dev-dataset/11_TileScan 6--Stage00'), PosixPath('/home/ishang/HPA-embedding/dev-dataset/10_R1--Stage01'), PosixPath('/home/ishang/HPA-embedding/dev-dataset/field--X01--Y00_image--L0000--S00--U08--V04--J17--E02--O02--X01--Y00--T0000--Z00--C0')]\n"
     ]
    }
   ],
   "source": [
    "image_paths = list(open(\"data-folder.txt\", \"r\"))\n",
    "image_paths = [Path(x.strip()) for x in image_paths]\n",
    "print(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def get_masks(segmentator, image_paths):\n",
    "    for image_path in image_paths:\n",
    "        if (image_paths / \"cellmask.png\").exists():\n",
    "            continue\n",
    "        channel_images = []\n",
    "        glob_channel_images = lambda image_path, c: list(glob(f\"{str(image_path)}/**/*{CHANNEL_NAMES[c]}.png\", recursive=True))\n",
    "        dapi_paths = sorted(glob_channel_images(image_path, DAPI))\n",
    "        tubl_paths = sorted(glob_channel_images(image_path, TUBL))\n",
    "        anln_paths = sorted(glob_channel_images(image_path, ANLN)) if ANLN is not None else None\n",
    "        \n",
    "        for dapi, tubl in zip(dapi_paths, tubl_paths):\n",
    "            assert str(dapi).split(CHANNEL_NAMES[DAPI])[0] == str(tubl).split(CHANNEL_NAMES[TUBL])[0], f\"File mismatch for {dapi} and {tubl}\"\n",
    "        if ANLN is not None and anln_paths is not None:\n",
    "            for dapi, anln in zip(dapi_paths, anln_paths):\n",
    "                assert str(dapi).split(CHANNEL_NAMES[DAPI])[0] == str(anln).split(CHANNEL_NAMES[ANLN])[0], f\"File mismatch for {dapi} and {anln}\"\n",
    "\n",
    "        load_image = lambda path_list: [cv2.imread(str(x), cv2.IMREAD_UNCHANGED) for x in path_list]\n",
    "        dapi_images = load_image(dapi_paths)\n",
    "        tubl_images = load_image(tubl_paths)\n",
    "        anln_images = load_image(anln_paths) if anln_paths is not None else None\n",
    "\n",
    "        images = [tubl_images, anln_images, dapi_images]\n",
    "        nuc_segmentation = segmentator.pred_nuclei(images[2])\n",
    "        cell_segmentation = segmentator.pred_cells(images)\n",
    "\n",
    "        # post-processing\n",
    "        nuclei_mask = label_nuclei(nuc_segmentation[0])\n",
    "        nuclei_mask, cell_mask = label_cell(\n",
    "            nuc_segmentation[0], cell_segmentation[0]\n",
    "        )\n",
    "\n",
    "        # apply preprocessing mask if the user want to merge nuclei\n",
    "        # in preprocess_masks get_single_cell_mask\n",
    "\n",
    "        assert set(np.unique(nuclei_mask)) == set(np.unique(cell_mask)), f\"Mask mismatch for {image_path}, nuclei: {np.unique(nuclei_mask)}, cell: {np.unique(cell_mask)}\"\n",
    "        assert np.max(nuclei_mask) > 0 and np.max(cell_mask) > 0, f\"No nuclei or cell mask found for {image_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_cell_mask(\n",
    "    cell_mask,\n",
    "    nuclei_mask,\n",
    "    # final_size=None, # resize the mask to final_size\n",
    "    rm_border=True, # removes cells touching the border\n",
    "    remove_size=1000,\n",
    "    dialation_radius=20,\n",
    "):\n",
    "    if rm_border:\n",
    "        nuclei_mask = segmentation.clear_border(nuclei_mask)\n",
    "        keep_value = np.unique(nuclei_mask)\n",
    "        borderedcellmask = np.array([[x_ in keep_value for x_ in x] for x in cell_mask]).astype(\"uint8\")\n",
    "        cell_mask = cell_mask * borderedcellmask\n",
    "        num_removed = len(keep_value) - len(np.unique(cell_mask))\n",
    "    else:\n",
    "        num_removed = 0\n",
    "\n",
    "    assert set(np.unique(nuclei_mask)) == set(np.unique(cell_mask))\n",
    "\n",
    "    # needs to be after clear border otherwise you get a boundary of nuclei that are still touching the edge\n",
    "    # maybe that is due to the interpolation method\n",
    "    # ideally this happens outside\n",
    "    # if final_size is not None:\n",
    "    #     nuclei_mask = cv2.resize(nuclei_mask, final_size, interpolation=cv2.INTER_NEAREST)\n",
    "    #     cell_mask = cv2.resize(cell_mask, final_size, interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "    ### see if nuclei are touching and merge them\n",
    "    bin_nuc_mask = (nuclei_mask > 0).astype(np.int8)\n",
    "    cls_nuc = morphology.closing(bin_nuc_mask, morphology.disk(dialation_radius))\n",
    "    # get the labels of touching nuclei\n",
    "    new_label_map = morphology.label(cls_nuc)\n",
    "    new_label_idx = np.unique(new_label_map)[1:]\n",
    "\n",
    "    new_cell_mask = np.zeros_like(cell_mask)\n",
    "    new_nuc_mask = np.zeros_like(nuclei_mask)\n",
    "    for new_label in new_label_idx:\n",
    "        # get the label of the touching nuclei\n",
    "        old_labels = np.unique(nuclei_mask[new_label_map == new_label])\n",
    "        old_labels = old_labels[old_labels != 0]\n",
    "\n",
    "        new_nuc_mask[np.isin(nuclei_mask, old_labels)] = new_label\n",
    "        new_cell_mask[np.isin(cell_mask, old_labels)] = new_label\n",
    "\n",
    "        # for old_label in old_labels:\n",
    "        #     new_cell_mask[cell_mask == old_label] = new_label\n",
    "        #     new_nuc_mask[nuclei_mask == old_label] = new_label\n",
    "\n",
    "    assert set(np.unique(new_nuc_mask)) == set(np.unique(new_cell_mask))\n",
    "\n",
    "    region_props = measure.regionprops(new_cell_mask, (new_cell_mask > 0).astype(np.uint8))\n",
    "    if len(region_props) == 0:\n",
    "        return new_cell_mask, new_nuc_mask, None, None\n",
    "    else:\n",
    "        bbox_array = np.array([x.bbox for x in region_props if x.area > remove_size])\n",
    "        ## convert x1,y1,x2,y2 to x,y,w,h\n",
    "        bbox_array[:, 2] = bbox_array[:, 2] - bbox_array[:, 0]\n",
    "        bbox_array[:, 3] = bbox_array[:, 3] - bbox_array[:, 1]\n",
    "\n",
    "        com_array = np.array([x.weighted_centroid for x in region_props if x.area > remove_size])\n",
    "        return new_cell_mask, new_nuc_mask, bbox_array, com_array, num_removed\n",
    "    # TODO somehow report the number removed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-prep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
